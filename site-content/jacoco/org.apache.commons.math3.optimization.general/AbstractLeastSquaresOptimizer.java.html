<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../.resources/report.css" type="text/css"/><link rel="shortcut icon" href="../.resources/report.gif" type="image/gif"/><title>AbstractLeastSquaresOptimizer.java</title><link rel="stylesheet" href="../.resources/prettify.css" type="text/css"/><script type="text/javascript" src="../.resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../.sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Apache Commons Math</a> &gt; <a href="index.source.html" class="el_package">org.apache.commons.math3.optimization.general</a> &gt; <span class="el_source">AbstractLeastSquaresOptimizer.java</span></div><h1>AbstractLeastSquaresOptimizer.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the &quot;License&quot;); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.commons.math3.optimization.general;

import org.apache.commons.math3.analysis.DifferentiableMultivariateVectorFunction;
import org.apache.commons.math3.analysis.FunctionUtils;
import org.apache.commons.math3.analysis.differentiation.DerivativeStructure;
import org.apache.commons.math3.analysis.differentiation.MultivariateDifferentiableVectorFunction;
import org.apache.commons.math3.exception.DimensionMismatchException;
import org.apache.commons.math3.exception.NumberIsTooSmallException;
import org.apache.commons.math3.exception.util.LocalizedFormats;
import org.apache.commons.math3.linear.ArrayRealVector;
import org.apache.commons.math3.linear.RealMatrix;
import org.apache.commons.math3.linear.DiagonalMatrix;
import org.apache.commons.math3.linear.DecompositionSolver;
import org.apache.commons.math3.linear.MatrixUtils;
import org.apache.commons.math3.linear.QRDecomposition;
import org.apache.commons.math3.linear.EigenDecomposition;
import org.apache.commons.math3.optimization.OptimizationData;
import org.apache.commons.math3.optimization.InitialGuess;
import org.apache.commons.math3.optimization.Target;
import org.apache.commons.math3.optimization.Weight;
import org.apache.commons.math3.optimization.ConvergenceChecker;
import org.apache.commons.math3.optimization.DifferentiableMultivariateVectorOptimizer;
import org.apache.commons.math3.optimization.PointVectorValuePair;
import org.apache.commons.math3.optimization.direct.BaseAbstractMultivariateVectorOptimizer;
import org.apache.commons.math3.util.FastMath;

/**
 * Base class for implementing least squares optimizers.
 * It handles the boilerplate methods associated to thresholds settings,
 * Jacobian and error estimation.
 * &lt;br/&gt;
 * This class constructs the Jacobian matrix of the function argument in method
 * {@link BaseAbstractMultivariateVectorOptimizer#optimize(int,
 * org.apache.commons.math3.analysis.MultivariateVectorFunction,OptimizationData[])
 * optimize} and assumes that the rows of that matrix iterate on the model
 * functions while the columns iterate on the parameters; thus, the numbers
 * of rows is equal to the dimension of the
 * {@link org.apache.commons.math3.optimization.Target Target} while
 * the number of columns is equal to the dimension of the
 * {@link org.apache.commons.math3.optimization.InitialGuess InitialGuess}.
 *
 * @deprecated As of 3.1 (to be removed in 4.0).
 * @since 1.2
 */
@Deprecated
public abstract class AbstractLeastSquaresOptimizer
    extends BaseAbstractMultivariateVectorOptimizer&lt;DifferentiableMultivariateVectorFunction&gt;
    implements DifferentiableMultivariateVectorOptimizer {
    /**
     * Singularity threshold (cf. {@link #getCovariances(double)}).
     * @deprecated As of 3.1.
     */
    @Deprecated
    private static final double DEFAULT_SINGULARITY_THRESHOLD = 1e-14;
    /**
     * Jacobian matrix of the weighted residuals.
     * This matrix is in canonical form just after the calls to
     * {@link #updateJacobian()}, but may be modified by the solver
     * in the derived class (the {@link LevenbergMarquardtOptimizer
     * Levenberg-Marquardt optimizer} does this).
     * @deprecated As of 3.1. To be removed in 4.0. Please use
     * {@link #computeWeightedJacobian(double[])} instead.
     */
    @Deprecated
    protected double[][] weightedResidualJacobian;
    /** Number of columns of the jacobian matrix.
     * @deprecated As of 3.1.
     */
    @Deprecated
    protected int cols;
    /** Number of rows of the jacobian matrix.
     * @deprecated As of 3.1.
     */
    @Deprecated
    protected int rows;
    /** Current point.
     * @deprecated As of 3.1.
     */
    @Deprecated
    protected double[] point;
    /** Current objective function value.
     * @deprecated As of 3.1.
     */
    @Deprecated
    protected double[] objective;
    /** Weighted residuals
     * @deprecated As of 3.1.
     */
    @Deprecated
    protected double[] weightedResiduals;
    /** Cost value (square root of the sum of the residuals).
     * @deprecated As of 3.1. Field to become &quot;private&quot; in 4.0.
     * Please use {@link #setCost(double)}.
     */
    @Deprecated
    protected double cost;
    /** Objective function derivatives. */
    private MultivariateDifferentiableVectorFunction jF;
    /** Number of evaluations of the Jacobian. */
    private int jacobianEvaluations;
    /** Square-root of the weight matrix. */
    private RealMatrix weightMatrixSqrt;

    /**
     * Simple constructor with default settings.
     * The convergence check is set to a {@link
     * org.apache.commons.math3.optimization.SimpleVectorValueChecker}.
     * @deprecated See {@link org.apache.commons.math3.optimization.SimpleValueChecker#SimpleValueChecker()}
     */
    @Deprecated
<span class="nc" id="L128">    protected AbstractLeastSquaresOptimizer() {}</span>

    /**
     * @param checker Convergence checker.
     */
    protected AbstractLeastSquaresOptimizer(ConvergenceChecker&lt;PointVectorValuePair&gt; checker) {
<span class="fc" id="L134">        super(checker);</span>
<span class="fc" id="L135">    }</span>

    /**
     * @return the number of evaluations of the Jacobian function.
     */
    public int getJacobianEvaluations() {
<span class="fc" id="L141">        return jacobianEvaluations;</span>
    }

    /**
     * Update the jacobian matrix.
     *
     * @throws DimensionMismatchException if the Jacobian dimension does not
     * match problem dimension.
     * @deprecated As of 3.1. Please use {@link #computeWeightedJacobian(double[])}
     * instead.
     */
    @Deprecated
    protected void updateJacobian() {
<span class="nc" id="L154">        final RealMatrix weightedJacobian = computeWeightedJacobian(point);</span>
<span class="nc" id="L155">        weightedResidualJacobian = weightedJacobian.scalarMultiply(-1).getData();</span>
<span class="nc" id="L156">    }</span>

    /**
     * Computes the Jacobian matrix.
     *
     * @param params Model parameters at which to compute the Jacobian.
     * @return the weighted Jacobian: W&lt;sup&gt;1/2&lt;/sup&gt; J.
     * @throws DimensionMismatchException if the Jacobian dimension does not
     * match problem dimension.
     * @since 3.1
     */
    protected RealMatrix computeWeightedJacobian(double[] params) {
<span class="fc" id="L168">        ++jacobianEvaluations;</span>

<span class="fc" id="L170">        final DerivativeStructure[] dsPoint = new DerivativeStructure[params.length];</span>
<span class="fc" id="L171">        final int nC = params.length;</span>
<span class="fc bfc" id="L172" title="All 2 branches covered.">        for (int i = 0; i &lt; nC; ++i) {</span>
<span class="fc" id="L173">            dsPoint[i] = new DerivativeStructure(nC, 1, i, params[i]);</span>
        }
<span class="fc" id="L175">        final DerivativeStructure[] dsValue = jF.value(dsPoint);</span>
<span class="fc" id="L176">        final int nR = getTarget().length;</span>
<span class="pc bpc" id="L177" title="1 of 2 branches missed.">        if (dsValue.length != nR) {</span>
<span class="nc" id="L178">            throw new DimensionMismatchException(dsValue.length, nR);</span>
        }
<span class="fc" id="L180">        final double[][] jacobianData = new double[nR][nC];</span>
<span class="fc bfc" id="L181" title="All 2 branches covered.">        for (int i = 0; i &lt; nR; ++i) {</span>
<span class="fc" id="L182">            int[] orders = new int[nC];</span>
<span class="fc bfc" id="L183" title="All 2 branches covered.">            for (int j = 0; j &lt; nC; ++j) {</span>
<span class="fc" id="L184">                orders[j] = 1;</span>
<span class="fc" id="L185">                jacobianData[i][j] = dsValue[i].getPartialDerivative(orders);</span>
<span class="fc" id="L186">                orders[j] = 0;</span>
            }
        }

<span class="fc" id="L190">        return weightMatrixSqrt.multiply(MatrixUtils.createRealMatrix(jacobianData));</span>
    }

    /**
     * Update the residuals array and cost function value.
     * @throws DimensionMismatchException if the dimension does not match the
     * problem dimension.
     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException
     * if the maximal number of evaluations is exceeded.
     * @deprecated As of 3.1. Please use {@link #computeResiduals(double[])},
     * {@link #computeObjectiveValue(double[])}, {@link #computeCost(double[])}
     * and {@link #setCost(double)} instead.
     */
    @Deprecated
    protected void updateResidualsAndCost() {
<span class="nc" id="L205">        objective = computeObjectiveValue(point);</span>
<span class="nc" id="L206">        final double[] res = computeResiduals(objective);</span>

        // Compute cost.
<span class="nc" id="L209">        cost = computeCost(res);</span>

        // Compute weighted residuals.
<span class="nc" id="L212">        final ArrayRealVector residuals = new ArrayRealVector(res);</span>
<span class="nc" id="L213">        weightedResiduals = weightMatrixSqrt.operate(residuals).toArray();</span>
<span class="nc" id="L214">    }</span>

    /**
     * Computes the cost.
     *
     * @param residuals Residuals.
     * @return the cost.
     * @see #computeResiduals(double[])
     * @since 3.1
     */
    protected double computeCost(double[] residuals) {
<span class="fc" id="L225">        final ArrayRealVector r = new ArrayRealVector(residuals);</span>
<span class="fc" id="L226">        return FastMath.sqrt(r.dotProduct(getWeight().operate(r)));</span>
    }

    /**
     * Get the Root Mean Square value.
     * Get the Root Mean Square value, i.e. the root of the arithmetic
     * mean of the square of all weighted residuals. This is related to the
     * criterion that is minimized by the optimizer as follows: if
     * &lt;em&gt;c&lt;/em&gt; if the criterion, and &lt;em&gt;n&lt;/em&gt; is the number of
     * measurements, then the RMS is &lt;em&gt;sqrt (c/n)&lt;/em&gt;.
     *
     * @return RMS value
     */
    public double getRMS() {
<span class="fc" id="L240">        return FastMath.sqrt(getChiSquare() / rows);</span>
    }

    /**
     * Get a Chi-Square-like value assuming the N residuals follow N
     * distinct normal distributions centered on 0 and whose variances are
     * the reciprocal of the weights.
     * @return chi-square value
     */
    public double getChiSquare() {
<span class="fc" id="L250">        return cost * cost;</span>
    }

    /**
     * Gets the square-root of the weight matrix.
     *
     * @return the square-root of the weight matrix.
     * @since 3.1
     */
    public RealMatrix getWeightSquareRoot() {
<span class="fc" id="L260">        return weightMatrixSqrt.copy();</span>
    }

    /**
     * Sets the cost.
     *
     * @param cost Cost value.
     * @since 3.1
     */
    protected void setCost(double cost) {
<span class="fc" id="L270">        this.cost = cost;</span>
<span class="fc" id="L271">    }</span>

    /**
     * Get the covariance matrix of the optimized parameters.
     *
     * @return the covariance matrix.
     * @throws org.apache.commons.math3.linear.SingularMatrixException
     * if the covariance matrix cannot be computed (singular problem).
     * @see #getCovariances(double)
     * @deprecated As of 3.1. Please use {@link #computeCovariances(double[],double)}
     * instead.
     */
    @Deprecated
    public double[][] getCovariances() {
<span class="nc" id="L285">        return getCovariances(DEFAULT_SINGULARITY_THRESHOLD);</span>
    }

    /**
     * Get the covariance matrix of the optimized parameters.
     * &lt;br/&gt;
     * Note that this operation involves the inversion of the
     * &lt;code&gt;J&lt;sup&gt;T&lt;/sup&gt;J&lt;/code&gt; matrix, where {@code J} is the
     * Jacobian matrix.
     * The {@code threshold} parameter is a way for the caller to specify
     * that the result of this computation should be considered meaningless,
     * and thus trigger an exception.
     *
     * @param threshold Singularity threshold.
     * @return the covariance matrix.
     * @throws org.apache.commons.math3.linear.SingularMatrixException
     * if the covariance matrix cannot be computed (singular problem).
     * @deprecated As of 3.1. Please use {@link #computeCovariances(double[],double)}
     * instead.
     */
    @Deprecated
    public double[][] getCovariances(double threshold) {
<span class="nc" id="L307">        return computeCovariances(point, threshold);</span>
    }

    /**
     * Get the covariance matrix of the optimized parameters.
     * &lt;br/&gt;
     * Note that this operation involves the inversion of the
     * &lt;code&gt;J&lt;sup&gt;T&lt;/sup&gt;J&lt;/code&gt; matrix, where {@code J} is the
     * Jacobian matrix.
     * The {@code threshold} parameter is a way for the caller to specify
     * that the result of this computation should be considered meaningless,
     * and thus trigger an exception.
     *
     * @param params Model parameters.
     * @param threshold Singularity threshold.
     * @return the covariance matrix.
     * @throws org.apache.commons.math3.linear.SingularMatrixException
     * if the covariance matrix cannot be computed (singular problem).
     * @since 3.1
     */
    public double[][] computeCovariances(double[] params,
                                         double threshold) {
        // Set up the Jacobian.
<span class="fc" id="L330">        final RealMatrix j = computeWeightedJacobian(params);</span>

        // Compute transpose(J)J.
<span class="fc" id="L333">        final RealMatrix jTj = j.transpose().multiply(j);</span>

        // Compute the covariances matrix.
<span class="fc" id="L336">        final DecompositionSolver solver</span>
            = new QRDecomposition(jTj, threshold).getSolver();
<span class="fc" id="L338">        return solver.getInverse().getData();</span>
    }

    /**
     * &lt;p&gt;
     * Returns an estimate of the standard deviation of each parameter. The
     * returned values are the so-called (asymptotic) standard errors on the
     * parameters, defined as {@code sd(a[i]) = sqrt(S / (n - m) * C[i][i])},
     * where {@code a[i]} is the optimized value of the {@code i}-th parameter,
     * {@code S} is the minimized value of the sum of squares objective function
     * (as returned by {@link #getChiSquare()}), {@code n} is the number of
     * observations, {@code m} is the number of parameters and {@code C} is the
     * covariance matrix.
     * &lt;/p&gt;
     * &lt;p&gt;
     * See also
     * &lt;a href=&quot;http://en.wikipedia.org/wiki/Least_squares&quot;&gt;Wikipedia&lt;/a&gt;,
     * or
     * &lt;a href=&quot;http://mathworld.wolfram.com/LeastSquaresFitting.html&quot;&gt;MathWorld&lt;/a&gt;,
     * equations (34) and (35) for a particular case.
     * &lt;/p&gt;
     *
     * @return an estimate of the standard deviation of the optimized parameters
     * @throws org.apache.commons.math3.linear.SingularMatrixException
     * if the covariance matrix cannot be computed.
     * @throws NumberIsTooSmallException if the number of degrees of freedom is not
     * positive, i.e. the number of measurements is less or equal to the number of
     * parameters.
     * @deprecated as of version 3.1, {@link #computeSigma(double[],double)} should be used
     * instead. It should be emphasized that {@code guessParametersErrors} and
     * {@code computeSigma} are &lt;em&gt;not&lt;/em&gt; strictly equivalent.
     */
    @Deprecated
    public double[] guessParametersErrors() {
<span class="fc bfc" id="L372" title="All 2 branches covered.">        if (rows &lt;= cols) {</span>
<span class="fc" id="L373">            throw new NumberIsTooSmallException(LocalizedFormats.NO_DEGREES_OF_FREEDOM,</span>
                                                rows, cols, false);
        }
<span class="fc" id="L376">        double[] errors = new double[cols];</span>
<span class="fc" id="L377">        final double c = FastMath.sqrt(getChiSquare() / (rows - cols));</span>
<span class="fc" id="L378">        double[][] covar = computeCovariances(point, 1e-14);</span>
<span class="fc bfc" id="L379" title="All 2 branches covered.">        for (int i = 0; i &lt; errors.length; ++i) {</span>
<span class="fc" id="L380">            errors[i] = FastMath.sqrt(covar[i][i]) * c;</span>
        }
<span class="fc" id="L382">        return errors;</span>
    }

    /**
     * Computes an estimate of the standard deviation of the parameters. The
     * returned values are the square root of the diagonal coefficients of the
     * covariance matrix, {@code sd(a[i]) ~= sqrt(C[i][i])}, where {@code a[i]}
     * is the optimized value of the {@code i}-th parameter, and {@code C} is
     * the covariance matrix.
     *
     * @param params Model parameters.
     * @param covarianceSingularityThreshold Singularity threshold (see
     * {@link #computeCovariances(double[],double) computeCovariances}).
     * @return an estimate of the standard deviation of the optimized parameters
     * @throws org.apache.commons.math3.linear.SingularMatrixException
     * if the covariance matrix cannot be computed.
     * @since 3.1
     */
    public double[] computeSigma(double[] params,
                                 double covarianceSingularityThreshold) {
<span class="fc" id="L402">        final int nC = params.length;</span>
<span class="fc" id="L403">        final double[] sig = new double[nC];</span>
<span class="fc" id="L404">        final double[][] cov = computeCovariances(params, covarianceSingularityThreshold);</span>
<span class="fc bfc" id="L405" title="All 2 branches covered.">        for (int i = 0; i &lt; nC; ++i) {</span>
<span class="fc" id="L406">            sig[i] = FastMath.sqrt(cov[i][i]);</span>
        }
<span class="fc" id="L408">        return sig;</span>
    }

    /** {@inheritDoc}
     * @deprecated As of 3.1. Please use
     * {@link BaseAbstractMultivariateVectorOptimizer#optimize(int,
     * org.apache.commons.math3.analysis.MultivariateVectorFunction,OptimizationData[])
     * optimize(int,MultivariateDifferentiableVectorFunction,OptimizationData...)}
     * instead.
     */
    @Override
    @Deprecated
    public PointVectorValuePair optimize(int maxEval,
                                         final DifferentiableMultivariateVectorFunction f,
                                         final double[] target, final double[] weights,
                                         final double[] startPoint) {
<span class="fc" id="L424">        return optimizeInternal(maxEval,</span>
                                FunctionUtils.toMultivariateDifferentiableVectorFunction(f),
                                new Target(target),
                                new Weight(weights),
                                new InitialGuess(startPoint));
    }

    /**
     * Optimize an objective function.
     * Optimization is considered to be a weighted least-squares minimization.
     * The cost function to be minimized is
     * &lt;code&gt;&amp;sum;weight&lt;sub&gt;i&lt;/sub&gt;(objective&lt;sub&gt;i&lt;/sub&gt; - target&lt;sub&gt;i&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;&lt;/code&gt;
     *
     * @param f Objective function.
     * @param target Target value for the objective functions at optimum.
     * @param weights Weights for the least squares cost computation.
     * @param startPoint Start point for optimization.
     * @return the point/value pair giving the optimal value for objective
     * function.
     * @param maxEval Maximum number of function evaluations.
     * @throws org.apache.commons.math3.exception.DimensionMismatchException
     * if the start point dimension is wrong.
     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException
     * if the maximal number of evaluations is exceeded.
     * @throws org.apache.commons.math3.exception.NullArgumentException if
     * any argument is {@code null}.
     * @deprecated As of 3.1. Please use
     * {@link BaseAbstractMultivariateVectorOptimizer#optimize(int,
     * org.apache.commons.math3.analysis.MultivariateVectorFunction,OptimizationData[])
     * optimize(int,MultivariateDifferentiableVectorFunction,OptimizationData...)}
     * instead.
     */
    @Deprecated
    public PointVectorValuePair optimize(final int maxEval,
                                         final MultivariateDifferentiableVectorFunction f,
                                         final double[] target, final double[] weights,
                                         final double[] startPoint) {
<span class="fc" id="L461">        return optimizeInternal(maxEval, f,</span>
                                new Target(target),
                                new Weight(weights),
                                new InitialGuess(startPoint));
    }

    /**
     * Optimize an objective function.
     * Optimization is considered to be a weighted least-squares minimization.
     * The cost function to be minimized is
     * &lt;code&gt;&amp;sum;weight&lt;sub&gt;i&lt;/sub&gt;(objective&lt;sub&gt;i&lt;/sub&gt; - target&lt;sub&gt;i&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;&lt;/code&gt;
     *
     * @param maxEval Allowed number of evaluations of the objective function.
     * @param f Objective function.
     * @param optData Optimization data. The following data will be looked for:
     * &lt;ul&gt;
     *  &lt;li&gt;{@link Target}&lt;/li&gt;
     *  &lt;li&gt;{@link Weight}&lt;/li&gt;
     *  &lt;li&gt;{@link InitialGuess}&lt;/li&gt;
     * &lt;/ul&gt;
     * @return the point/value pair giving the optimal value of the objective
     * function.
     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException if
     * the maximal number of evaluations is exceeded.
     * @throws DimensionMismatchException if the target, and weight arguments
     * have inconsistent dimensions.
     * @see BaseAbstractMultivariateVectorOptimizer#optimizeInternal(int,
     * org.apache.commons.math3.analysis.MultivariateVectorFunction,OptimizationData[])
     * @since 3.1
     * @deprecated As of 3.1. Override is necessary only until this class's generic
     * argument is changed to {@code MultivariateDifferentiableVectorFunction}.
     */
    @Deprecated
    protected PointVectorValuePair optimizeInternal(final int maxEval,
                                                    final MultivariateDifferentiableVectorFunction f,
                                                    OptimizationData... optData) {
        // XXX Conversion will be removed when the generic argument of the
        // base class becomes &quot;MultivariateDifferentiableVectorFunction&quot;.
<span class="fc" id="L499">        return super.optimizeInternal(maxEval, FunctionUtils.toDifferentiableMultivariateVectorFunction(f), optData);</span>
    }

    /** {@inheritDoc} */
    @Override
    protected void setUp() {
<span class="fc" id="L505">        super.setUp();</span>

        // Reset counter.
<span class="fc" id="L508">        jacobianEvaluations = 0;</span>

        // Square-root of the weight matrix.
<span class="fc" id="L511">        weightMatrixSqrt = squareRoot(getWeight());</span>

        // Store least squares problem characteristics.
        // XXX The conversion won't be necessary when the generic argument of
        // the base class becomes &quot;MultivariateDifferentiableVectorFunction&quot;.
        // XXX &quot;jF&quot; is not strictly necessary anymore but is currently more
        // efficient than converting the value returned from &quot;getObjectiveFunction()&quot;
        // every time it is used.
<span class="fc" id="L519">        jF = FunctionUtils.toMultivariateDifferentiableVectorFunction((DifferentiableMultivariateVectorFunction) getObjectiveFunction());</span>

        // Arrays shared with &quot;private&quot; and &quot;protected&quot; methods.
<span class="fc" id="L522">        point = getStartPoint();</span>
<span class="fc" id="L523">        rows = getTarget().length;</span>
<span class="fc" id="L524">        cols = point.length;</span>
<span class="fc" id="L525">    }</span>

    /**
     * Computes the residuals.
     * The residual is the difference between the observed (target)
     * values and the model (objective function) value.
     * There is one residual for each element of the vector-valued
     * function.
     *
     * @param objectiveValue Value of the the objective function. This is
     * the value returned from a call to
     * {@link #computeObjectiveValue(double[]) computeObjectiveValue}
     * (whose array argument contains the model parameters).
     * @return the residuals.
     * @throws DimensionMismatchException if {@code params} has a wrong
     * length.
     * @since 3.1
     */
    protected double[] computeResiduals(double[] objectiveValue) {
<span class="fc" id="L544">        final double[] target = getTarget();</span>
<span class="fc bfc" id="L545" title="All 2 branches covered.">        if (objectiveValue.length != target.length) {</span>
<span class="fc" id="L546">            throw new DimensionMismatchException(target.length,</span>
                                                 objectiveValue.length);
        }

<span class="fc" id="L550">        final double[] residuals = new double[target.length];</span>
<span class="fc bfc" id="L551" title="All 2 branches covered.">        for (int i = 0; i &lt; target.length; i++) {</span>
<span class="fc" id="L552">            residuals[i] = target[i] - objectiveValue[i];</span>
        }

<span class="fc" id="L555">        return residuals;</span>
    }

    /**
     * Computes the square-root of the weight matrix.
     *
     * @param m Symmetric, positive-definite (weight) matrix.
     * @return the square-root of the weight matrix.
     */
    private RealMatrix squareRoot(RealMatrix m) {
<span class="pc bpc" id="L565" title="1 of 2 branches missed.">        if (m instanceof DiagonalMatrix) {</span>
<span class="fc" id="L566">            final int dim = m.getRowDimension();</span>
<span class="fc" id="L567">            final RealMatrix sqrtM = new DiagonalMatrix(dim);</span>
<span class="fc bfc" id="L568" title="All 2 branches covered.">            for (int i = 0; i &lt; dim; i++) {</span>
<span class="fc" id="L569">               sqrtM.setEntry(i, i, FastMath.sqrt(m.getEntry(i, i)));</span>
            }
<span class="fc" id="L571">            return sqrtM;</span>
        } else {
<span class="nc" id="L573">            final EigenDecomposition dec = new EigenDecomposition(m);</span>
<span class="nc" id="L574">            return dec.getSquareRoot();</span>
        }
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.5.201505241946</span></div></body></html>